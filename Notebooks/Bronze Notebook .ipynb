{"cells":[{"cell_type":"code","source":["# Welcome to your new notebook\n","# Type here in the cell editor to add code!\n","import requests\n","import json\n","from datetime import date, timedelta"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":3,"statement_ids":[3],"state":"finished","livy_statement_state":"available","session_id":"8dd537e7-9d55-41e0-a937-d0977146e6d1","normalized_state":"finished","queued_time":"2025-05-08T11:56:12.8009697Z","session_start_time":"2025-05-08T11:56:12.8023997Z","execution_start_time":"2025-05-08T11:56:25.6161156Z","execution_finish_time":"2025-05-08T11:56:26.1820915Z","parent_msg_id":"e4bfd68a-2f75-4675-acee-a5665995f97f"},"text/plain":"StatementMeta(, 8dd537e7-9d55-41e0-a937-d0977146e6d1, 3, Finished, Available, Finished)"},"metadata":{}}],"execution_count":1,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"6610f873-3e36-4bdd-996c-7d95be2b3860"},{"cell_type":"code","source":["start_date = date.today() - timedelta(7) # 7 days\n","end_date = date.today() - timedelta(1)"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":4,"statement_ids":[4],"state":"finished","livy_statement_state":"available","session_id":"8dd537e7-9d55-41e0-a937-d0977146e6d1","normalized_state":"finished","queued_time":"2025-05-08T11:56:31.386881Z","session_start_time":null,"execution_start_time":"2025-05-08T11:56:31.3885943Z","execution_finish_time":"2025-05-08T11:56:31.740805Z","parent_msg_id":"cd3f9f63-08db-4811-a350-691277778f41"},"text/plain":"StatementMeta(, 8dd537e7-9d55-41e0-a937-d0977146e6d1, 4, Finished, Available, Finished)"},"metadata":{}}],"execution_count":2,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"6f58ca19-cf93-43c7-9cb4-554aa6cfd6ea"},{"cell_type":"code","source":["# Construct the API URL with start and end dates provided by Data Factory, formatted for geojson output.\n","url = f\"https://earthquake.usgs.gov/fdsnws/event/1/query?format=geojson&starttime={start_date}&endtime={end_date}\"\n"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":5,"statement_ids":[5],"state":"finished","livy_statement_state":"available","session_id":"8dd537e7-9d55-41e0-a937-d0977146e6d1","normalized_state":"finished","queued_time":"2025-05-08T11:56:34.6812821Z","session_start_time":null,"execution_start_time":"2025-05-08T11:56:34.6829656Z","execution_finish_time":"2025-05-08T11:56:35.0696097Z","parent_msg_id":"2cbe4cff-14b9-416b-87a4-ce44b2eed747"},"text/plain":"StatementMeta(, 8dd537e7-9d55-41e0-a937-d0977146e6d1, 5, Finished, Available, Finished)"},"metadata":{}}],"execution_count":3,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"ad49d413-452c-47fe-959f-47de50f6b7a4"},{"cell_type":"code","source":["try:\n","    # Make the GET request to fetch data\n","    response = requests.get(url)\n","\n","    # Check if the request was successful\n","    response.raise_for_status()  # Raise HTTPError for bad responses (4xx or 5xx)\n","    data = response.json().get('features', [])\n","\n","    if not data:\n","        print(\"No data returned for the specified date range.\")\n","    else:\n","        # Specify the file name (and path if needed)\n","        file_path = f'/lakehouse/default/Files/{start_date}_earthquake_data.json'\n","\n","        # Save the JSON data\n","        with open(file_path, 'w') as file:\n","            json.dump(data, file, indent=4)\n","        print(f\"Data successfully saved to {file_path}\")\n","except requests.exceptions.RequestException as e:\n","    print(f\"Error fetching data from API: {e}\")"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":6,"statement_ids":[6],"state":"finished","livy_statement_state":"available","session_id":"8dd537e7-9d55-41e0-a937-d0977146e6d1","normalized_state":"finished","queued_time":"2025-05-08T11:56:37.7000187Z","session_start_time":null,"execution_start_time":"2025-05-08T11:56:37.7017272Z","execution_finish_time":"2025-05-08T11:56:40.391736Z","parent_msg_id":"34de8a2e-fcfc-49fa-81e2-14c3ff4820ac"},"text/plain":"StatementMeta(, 8dd537e7-9d55-41e0-a937-d0977146e6d1, 6, Finished, Available, Finished)"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Data successfully saved to /lakehouse/default/Files/2025-05-01_earthquake_data.json\n"]}],"execution_count":4,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"43434547-e085-44ab-8fc4-2bb1b5a98e32"}],"metadata":{"kernel_info":{"name":"synapse_pyspark"},"kernelspec":{"name":"synapse_pyspark","language":"Python","display_name":"Synapse PySpark"},"language_info":{"name":"python"},"microsoft":{"language":"python","language_group":"synapse_pyspark","ms_spell_check":{"ms_spell_check_language":"en"}},"nteract":{"version":"nteract-front-end@1.0.0"},"spark_compute":{"compute_id":"/trident/default","session_options":{"conf":{"spark.synapse.nbs.session.timeout":"1200000"}}},"dependencies":{"lakehouse":{"known_lakehouses":[{"id":"6a9e2802-97f9-431a-8698-a8c9f0d610e4"}],"default_lakehouse":"6a9e2802-97f9-431a-8698-a8c9f0d610e4","default_lakehouse_name":"earthquake_lakehouse","default_lakehouse_workspace_id":"d2e7c303-b6b4-4096-9ea3-4a4236ba977b"}}},"nbformat":4,"nbformat_minor":5}